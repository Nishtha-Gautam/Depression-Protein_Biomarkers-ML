{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL3M1LPF3PrR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from shutil import copyfile (only if you want to save predictions in google drive)\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/ML protein biomarkers IGIB/\"\n",
        "data_path = os.path.join(base_dir, \"lasso_110.csv\")\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv(data_path)\n",
        "y = df[\"severe_single_episode\"].values\n",
        "X = df.drop(columns=[\"severe_single_episode\"]).values\n",
        "feature_names = df.drop(columns=[\"severe_single_episode\"]).columns\n",
        "\n",
        "# Splitting Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to Save Predictions and Print Metrics\n",
        "def save_predictions(model_name, y_train, y_test, train_preds, test_preds, train_probs, test_probs):\n",
        "    result_dir = os.path.join(base_dir, model_name)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, train_preds)\n",
        "    test_acc = accuracy_score(y_test, test_preds)\n",
        "    train_auc = roc_auc_score(y_train, train_probs)\n",
        "    test_auc = roc_auc_score(y_test, test_probs)\n",
        "\n",
        "    print(f\"\\nðŸ“Š {model_name.upper()} Metrics\")\n",
        "    print(f\"Train Accuracy: {train_acc:.4f}, ROC-AUC: {train_auc:.4f}\")\n",
        "    print(f\"Test  Accuracy: {test_acc:.4f}, ROC-AUC: {test_auc:.4f}\")\n",
        "\n",
        "    train_metrics = pd.DataFrame({\"Metric\": [\"Accuracy\", \"ROC-AUC\"], \"Value\": [train_acc, train_auc]})\n",
        "    test_metrics = pd.DataFrame({\"Metric\": [\"Accuracy\", \"ROC-AUC\"], \"Value\": [test_acc, test_auc]})\n",
        "\n",
        "    train_metrics.to_csv(os.path.join(result_dir, \"train_results.csv\"), index=False)\n",
        "    test_metrics.to_csv(os.path.join(result_dir, \"test_results.csv\"), index=False)\n",
        "\n",
        "    # Save predictions\n",
        "    pd.DataFrame({\"True\": y_train, \"Predicted\": train_preds, \"Probability\": train_probs}).to_csv(\n",
        "        os.path.join(result_dir, \"train_predictions.csv\"), index=False)\n",
        "    pd.DataFrame({\"True\": y_test, \"Predicted\": test_preds, \"Probability\": test_probs}).to_csv(\n",
        "        os.path.join(result_dir, \"test_predictions.csv\"), index=False)\n",
        "\n",
        "    # To save in Google Drive (commented)\n",
        "    # copyfile(os.path.join(result_dir, \"test_predictions.csv\"), \"/content/drive/MyDrive/test_predictions.csv\")\n",
        "\n",
        "# ROC Curve Collection\n",
        "roc_data = {}\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"\\nðŸ” Logistic Regression\")\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "train_probs = logreg.predict_proba(X_train)[:, 1]\n",
        "test_probs = logreg.predict_proba(X_test)[:, 1]\n",
        "train_preds = (train_probs > 0.5).astype(int)\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "save_predictions(\"logistic_regression\", y_train, y_test, train_preds, test_preds, train_probs, test_probs)\n",
        "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
        "roc_data[\"Logistic Regression\"] = (fpr, tpr)\n",
        "\n",
        "# Feature importance\n",
        "logreg_importance = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": np.abs(logreg.coef_[0])\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "logreg_importance.to_csv(os.path.join(base_dir, \"logistic_regression\", \"feature_importance.csv\"), index=False)\n",
        "\n",
        "with open(os.path.join(base_dir, \"logistic_regression\", \"logreg_model.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(logreg, f)\n",
        "\n",
        "# SVM\n",
        "print(\"\\nðŸ” SVM (Linear Kernel)\")\n",
        "svm = SVC(kernel=\"linear\", probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "train_probs = svm.predict_proba(X_train)[:, 1]\n",
        "test_probs = svm.predict_proba(X_test)[:, 1]\n",
        "train_preds = (train_probs > 0.5).astype(int)\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "save_predictions(\"svm\", y_train, y_test, train_preds, test_preds, train_probs, test_probs)\n",
        "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
        "roc_data[\"SVM\"] = (fpr, tpr)\n",
        "\n",
        "with open(os.path.join(base_dir, \"svm\", \"svm_model.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(svm, f)\n",
        "\n",
        "svm_importance = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": np.abs(svm.coef_[0])\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "svm_importance.to_csv(os.path.join(base_dir, \"svm\", \"feature_importance.csv\"), index=False)\n",
        "\n",
        "# MLP\n",
        "print(\"\\nðŸ” MLP (Keras)\")\n",
        "model = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_dim=X_train.shape[1]),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=0)\n",
        "\n",
        "train_probs = model.predict(X_train).ravel()\n",
        "test_probs = model.predict(X_test).ravel()\n",
        "train_preds = (train_probs > 0.5).astype(int)\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "save_predictions(\"deep_learning\", y_train, y_test, train_preds, test_preds, train_probs, test_probs)\n",
        "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
        "roc_data[\"Deep Learning\"] = (fpr, tpr)\n",
        "\n",
        "model.save(os.path.join(base_dir, \"deep_learning\", \"dl_model.h5\"))\n",
        "\n",
        "# Feature importance (sklearn MLP + permutation)\n",
        "print(\"Computing permutation importance for MLP...\")\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_sklearn = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300)\n",
        "mlp_sklearn.fit(X_train, y_train)\n",
        "perm_importance = permutation_importance(mlp_sklearn, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "mlp_importance = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": perm_importance.importances_mean\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "mlp_importance.to_csv(os.path.join(base_dir, \"deep_learning\", \"feature_importance.csv\"), index=False)\n",
        "\n",
        "# Plot Combined ROC-AUC\n",
        "print(\"\\nðŸ“ˆ Plotting Combined ROC-AUC Curve\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "for name, (fpr, tpr) in roc_data.items():\n",
        "    plt.plot(fpr, tpr, label=f\"{name}\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC-AUC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_dir, \"combined_roc_auc.png\"))\n",
        "# plt.savefig(\"/content/drive/MyDrive/combined_roc_auc.png\")  # Save to Google Drive\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… All models processed, predictions saved, and ROC curve plotted!\")\n"
      ]
    }
  ]
}